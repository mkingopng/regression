
# lecture 1 notes
- measuring the quality of a model's fit using MSE
- then we test on the test set, data previously not used to train/fit the model
- the concept of overfitting: divergence of train MSE and test MSE
- the bias - variance trade off, the optimal balance of which coincides with the minimal test MSE
- we require a **loss function** for penalizing errors in prediction
- the concept of cross validation

# lecture 2 notes

# extra videos

# text book

# translate all exercises into python

# ed notes into latex


# Bruce Beranger Lecture Notes (4 hours)

