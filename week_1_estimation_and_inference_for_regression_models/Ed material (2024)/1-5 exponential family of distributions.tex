%! Author = noone
%! Date = 1/21/24

% Preamble
\documentclass[11pt]{article}

% Remove paragraph indentation
\setlength{\parindent}{0pt}

% Increase space between paragraphs
\setlength{\parskip}{1em}  % Adjust the value as needed

% Discourage hyphenation
\hyphenpenalty=10000
\exhyphenpenalty=10000

% Packages
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}

% Document
\begin{document}

\section{Exponential family of distributions}

\textbf{Definition:}
Let \(Y\) be a random variable with values in \(\mathbb{R} \), \( \mathbb{N}_0 \), or \( \mathbb{Z}\) and suppose its probability distribution $f(y;\theta)$ depends on a single parameter \(\theta\). Then the distribution belongs to the exponential family if it admits the form

\begin{equation}
    \[f(y; \theta) = s(y)t(\theta)e^{a(y)b(\theta)}\]
\end{equation}

for some functions \(s\), \(t\), \(a\), and \(b\).

Another way of writing this is

\[f(y; \theta) = \exp[a(y)b(\theta) + c(\theta) + d(y)]\]

where \(s(y) = e^{d(y)}\) and \(t(\theta) = e^{c(\theta)}\).

\begin{itemize}
    \item If \(a(y) = y\), the distribution of \(Y\) is called canonical.
    \item If the distribution is in its canonical form, \(b(\theta)\) is called the natural parameter of the distribution.
    \item If there are other parameters in addition to \(\theta\), they are usually called nuisance parameters and they can be functions of \(a\), \(b\), \(c\), and \(d\).
\end{itemize}

Notice that many well-known distributions belong to the exponential family.

\section*{Binomial distribution}

Suppose \(Y \sim \text{Bin}(n, p)\). The probability of getting exactly \(y\) successes in \(n\) trials is given by the probability mass function:

\[f(y \mid p) = \binom{n}{y} p^y (1 - p)^{n - y}\]

for \( y \in \{0, 1, \ldots, n\} \).

Assume that \(p\) is the parameter of interest which indicates the probability of success in a single experiment and that we know \(n\).

\textbf{Think:} Does the Binomial belong to the Exponential family of distributions?

The probability function can be rewritten as

\[f(y \mid p) = \exp \left[ y \log p - y \log(1 - p) + n \log(1 - p) + \log \binom{n}{y} \right]\]

this is of the form in equation (1.5.1) with

\[a(y) = y, \quad b(p) = \log \left( \frac{1}{p} - 1 \right), \quad c(p) = n \log(1 - p), \quad d(y) &= \log \binom{n}{y}\]

\textbf{The binomial distribution} is used as a model for observations of a process with binary outcomes: either success or failure. For example, it can be used to model the number of successes in a fixed number of trials in a process where each trial independently results in a success with the same probability \(p\).
\begin{enumerate}
    \item The number of candidates who pass a test - the possible outcomes for each candidate being to pass or to fail
    \item The number of patients with some disease who are alive at a specified time since diagnosis - the possible outcomes being survival or death
\end{itemize}

\section{Normal distribution}

Now, let's consider the Normal (or Gaussian) distribution, which is perhaps the most widely used distribution in statistics. The normal distribution is defined for a random variable \(Y\) with mean \(\mu\) and variance \(\sigma^2\), in the space $\mathbb{R}$denoted as \(Y \sim N(\mu, \sigma^2)\).

The probability density function (pdf) of the normal distribution is given by:

\[f(y \mid \mu, \sigma) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left( -\frac{1}{2\sigma^2} (y - \mu)^2 \right)\]

\textbf{Think:} Does the normal distribution belong to the exponential family of distributions?

the pdf can be rewritten in exponential family form:

\[f(y \mid \mu, \sigma) = \exp\left[ -\frac{y^2}{2\sigma^2} + \frac{y\mu}{\sigma^2} - \frac{\mu^2}{2\sigma^2} - \dfrac{1}{2} \log(2 \pi \sigma^2) \right]\]

where:

\[a(y) = y, \quad b(\mu) = \dfrac{\mu}{\sigma^2}, \quad c(\mu) = -\dfrac{\mu^2}{2\sigma^2} - \dfrac{1}{2} \log(2\pi\sigma^2), \quad d(y) = -\frac{y^2}{2\sigma^2}\]

The normal distribution is used to model continuous data with symmetric distribution. The normal distribution is common in applications, since:

\begin{enumerate}
    \item Many phenomena are well described by the normal distribution, ex. height or blood pressure of people;
    \item Even if data are not normal, the average or total of a random sample of values will be approximately normally distributed (Central Limit Theorem);
    \item Statistical theory is developed in a large extent for the Normal distribution.
\end{enumerate}

\section{Poisson distribution}

\section{Poisson distribution}

A random variable with positive values \(Y\) is Poisson with mean \(\lambda > 0\), denoted as \(Y \sim \text{Pois}(\lambda) \), if it has probability density function

\[f(y \mid \lambda) = \frac{\lambda^y}{e^{\lambda}y!}\]

\textbf{Think:} Does the Poisson distribution belong to the Exponential family?

The probability function can be rewritten in the exponential family form:

\[f(y \mid \lambda) = \exp\left(y \log \lambda - \lambda - \log y! \right)\]

where:

\[a(y) = y, b(\lambda) = \log \lambda, c(\lambda) = -\lambda, d(y) = -\log(y!)\]

The Poisson distribution provides a suitable model for count data and expresses the probability of a given number of events occurring in a fixed interval of time and/or space if these events occur with a known average rate and independently of the time since the last event. Examples include:

\begin{enumerate}
    \item The number of medical conditions reported by a person.
    \item The number of tropical cyclones during a season.
    \item The number of spelling mistakes on the page of a newspaper.
    \item The number of faulty components in a computer or in a batch of manufactured items.
\end{enumerate}

\section{Properties of distributions in the exponential family}

The expected value and variance of \( a(Y) \) for a distribution in the exponential family are given by the following formulas:

\[\mathbb{E}[a(Y)] = -\frac{c'(\theta)}{b'(\theta)}\]

and

\[\mathbb{V}\text{ar}[a(Y)] = \frac{b''(\theta)c'(\theta) - c''(\theta)b'(\theta)}{b'(\theta)^3}\]

You may want to see how these results were derived.

\section{Score and information}

We now formally introduce the statistics score and information.

The log-likelihood function for the exponential family is given by:

\[\ell(\theta; y) = a(y)b(\theta) + c(\theta) + d(y)\]

The score statistic is defined as:

\[U(\theta; y) = \frac{d\ell(\theta; y)}{d\theta} = a(y)b'(\theta) + c'(\theta)\]

It depends on \( y \) and may hence be interpreted as a random variable:

\[U := U(\theta; Y) = a(Y)b'(\theta) + c'(\theta)\]

The expected value of the score statistic \(U\) is

\[\mathbb{E}[U] = b'(\theta)E[a(Y)] + c'(\theta) = 0\]

because if we use equation (1.5.5)

\[\mathbb{E}[U] = b'(\theta) \left[-\frac{c'(\theta)}{b'(\theta)}\right] + c'(\theta) = 0\]

The variance of the score statistic \(U\) is called the information, denoted by \(\mathcal{I}\):

\[\mathcal{I} = \mathbb{V}\text{ar}(U) = b'(\theta)^2\mathbb{V}\text{ar}[a(Y)] = \frac{b''(\theta)c'(\theta) - c''(\theta)}{b'(\theta)^2}\]

Another property of the score function \(U\) is:

\[\mathbb{E}(U^2) = \mathbb{V}\text{ar}(U) = - \mathbb{E} \left(\frac{dU}{d\theta}\right)\]

The first equality follows from the general result \(\mathbb{V}\text{ar}(X) = \mathbb{E}(X^2) - [\mathbb{E}(X)]^2\) valid for any random variable, and \(\mathbb{E}(U) = 0\).

To see the second equality note that:
\begin{align}
    \mathbb{E} \left(\frac{dU}{dÎ¸}\right) &= \mathbb{E} \left(a(Y)b''(\theta) + c''(\theta)\right) \nonumber \\
    &= b''(\theta)\mathbb{E}[a(Y)] + c''(\theta) \nonumber \\
    &= b'' (\theta) \left[-\dfrac{c'(\theta)}{b'(\theta)}\right] + c''(\theta) \nonumber \\
    &= -\mathbb{V}\text{ar}(U) \nonumber \\
    &= -\mathcal{I} \nonumber
\end{align}

\section*{Pressure example}

Let's consider back the example with the times to failure of Kevlar epoxy strand pressure.

The Weibull distribution belongs to the exponential family since its pdf

\[f(y; \lambda, \theta) = \dfrac{\lambda}{\theta^\lambda} y^{\lambda - 1} \exp\left[-\left(\frac{y}{\theta}\right)^\lambda\right]\]

can be rewritten as

\[f(y; \theta) = \exp \left[ \log \lambda + (\lambda -1) \log y - \lambda \log \theta - \left(\dfrac{y}{\theta}\right)^\lambda\right]\]

with

\[a(y) = y^\lambda, \quad b(\theta) = -\theta^{-\lambda}, \quad c(\theta) = \log \lambda - \lambda \log \theta, \quad d(y) = (\lambda - 1) \log y\]

where \(\lambda\) is a nuisance parameter.

\end{document}
